Association Rules for Anomaly Detection and Root Cause Analysis in Process Executions
=============

Prototypical implementation for the submission: Kristof Böhmer and Stefanie Rinderle-Ma: Association Rules for Anomaly Detection and Root Cause Analysis in Process Executions. Accepted for CAISE 2018.

The given prototypical implementation of the presented unsupervised anomaly detection heuristic was applied during the evaluation of the submission. It analyzes process execution logs to create a signature (based on association rules) which enables to identify anomalies in process execution traces. Further, it contains additional algorithms which were only utilized during the evaluation (e.g., to analyze the anomaly detection performance or to perform a cross validation). Finally, it holds a helper project with contains auxiliary functions which ease the handling of collections but also additional supportive data structures. The main projects are:

ReadData
---------

The implementation was split into multiple projects. First, the **ReadData** project which enables to read and prepare information from XES logs as input for the following steps. Hereby, it especially focuses on real life logs, i.e., BPIC 2015 and HEP. Further, details on these log sources are given in the paper. Note, each log utilizes different parameter names and approaches to encode aspects, such as, the start and end of activity executions. Hence, the respective log source can be configured based on the BehaviourSource enumeration as BPIC or HEP. Further the ReadData project also holds a Config class which contains all the configuration values utilizes by the projects described in the following (e.g., the maximum rule length). 

RuleMining
---------

Secondly, the **RuleMining** project implements a rule mining approach which was inspired by the well known Apriori algorithm. Further this project also holds the definition of the Anomaly Detection Association Rules (ADAR) for each rule type to mine control flow, temporal, and resource behavior from the given log files as rules. In accordance to the description in the paper this project starts by initializing the final signature (rule set, resp.) with minimal rules (i.e., each rule contains only a single condition) based on the events in the given log files. Subsequently, iterative rule extension and verification steps are applied. Rule extension extends given rules by adding additional conditions to generate novel rule candidates. These candidates are subsequently analyzed to determine their support, if the support is found as being below a user configured threshold it is not integrated in the final signature. By repeating the last two steps multiple times in a row, rules which a user chosen length are generated. 

AnomalyDetection
---------

Thirdly, the **AnomalyDetection** project applies the mined rules to determine if a given process execution trace is anomalous or not. For this it contains code to incorporate all types of rules generated by the rule mining project (i.e. rules that focus on control, temporal, or resource behavior). Assume that a trace t' is given and should be classified either as anomalous or not. For this, first, a trace t is identified in the initially given XES log which is most similar to t’. Secondly, it is determined which rules are supported by the behavior given in t and t'. Thirdly, the overall support of the rules which are either found to be supported or not is individually aggregated. Here, the support of a rule is equal to the percentage of traces in the signature generation data which comply to that rule. Finally, if it is found that the aggregated support of the supported rules of t' is below the comparable value for t then t' is identified as anomalous. This also enables to report additional details for each identified anomaly. For example, which rules were supported and which were not but also the anomaly severity. The latter is derived from the aggregated rule support. Hereby, experts can be supported when they are striving to identify the root cause of a reported anomaly.

Evaluation
---------

Fourthly, the **Evaluation** project combines all the results from the other projects. Initially, it reads process behavior from process execution logs and splits this behavior randomly into training and testing data. Subsequently, the training data is mined to create an anomaly detection signature based on association rules. Afterwards, the testing data is partially enriched with anomalies so that a cross validation can be performed. Hereby, it is verified if the enriched and normal training data traces can be successfully differentiated as anomalous or non-anomalous. Further, this information is utilized to calculate performance metrics (i.e., True Positive, True Negative, False Positive, and False Negative) which are required to assess the anomaly detection performance of the presented approach. Note, during running the evaluation it was ensured that we analyze roughly the same data amount for each log source. Hereby, we can analyze how the complexity of the data (e.g., the dynamics in each trace, which can not be controlled) influences the results "independently" from the overall amount of data which can be controlled.


